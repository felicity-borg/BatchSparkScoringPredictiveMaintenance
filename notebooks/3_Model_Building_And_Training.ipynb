{"cells":[{"cell_type":"markdown","source":["# Model Building"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dde7bbaa-6e43-4ad3-9906-ba471197c78c"}}},{"cell_type":"markdown","source":["### Setup\n\nThe `2_Feature_Engineering` notebook takes parameters for which model to build (model), where to store the training data (features_table), and the start (start_date) and end (to_date) dates to use when creating the training data. \n\nUsing these parameters, it creates the training data by calling the `./notebooks/2_Feature_Engineering` with the correct parameters. When the `./notebooks/2_Feature_Engineering` notebook completes, we can start running the other cells to build our model."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d7c900cd-e61f-4eca-a1e1-c4b7433de1a2"}}},{"cell_type":"code","source":["from pyspark.sql import SparkSession\nspark = SparkSession.builder.getOrCreate()\n\n#Used data files\n# This is the default feature training data file.\ntraining_table= 'training_data'\n# The model we are building is a Random Forest\nmodel_type = 'RandomForest' \n\n#Databricks parameters to customize the runs\n# Input widgets allow you to add parameters to your notebooks and dashboards\ndbutils.widgets.removeAll()\ndbutils.widgets.text(\"features_table\", training_table)\ndbutils.widgets.text(\"model\", model_type)\ndbutils.widgets.text(\"start_date\", '2000-01-01')\ndbutils.widgets.text(\"to_date\", '2015-10-30')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"635e1b89-77e3-4cff-ad29-587d04b6a48b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":["Model","Testing_table"],"addedWidgets":{"features_table":{"name":"features_table","label":null,"widgetType":"text","options":{"widgetType":"text","validationRegex":null},"defaultValue":"training_data"},"model":{"name":"model","label":null,"widgetType":"text","options":{"widgetType":"text","validationRegex":null},"defaultValue":"RandomForest"},"start_date":{"name":"start_date","label":null,"widgetType":"text","options":{"widgetType":"text","validationRegex":null},"defaultValue":"2000-01-01"},"to_date":{"name":"to_date","label":null,"widgetType":"text","options":{"widgetType":"text","validationRegex":null},"defaultValue":"2015-10-30"}},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Feature Engineering\n\nThe `2_Feature_Engineering` notebook run below creates a labeled training data set using the parameters `start_date` and `to_date` to select the time period for training. This data set is stored in the `features_table` specified. After this cell completes, you should see the dataset named `training_data` under the Databricks `Data` icon."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"99667fc8-bf5c-4a66-b237-a7992223c419"}}},{"cell_type":"code","source":["dbutils.notebook.run(\"2_Feature_Engineering\", 600, {\"features_table\": dbutils.widgets.get(\"features_table\"), \n                                                     \"start_date\": dbutils.widgets.get(\"start_date\"), \n                                                     \"to_date\": dbutils.widgets.get(\"to_date\")})"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"78696193-c38a-4cbf-b1bf-4c9135fa1d7d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{"features_table":"training_data","start_date":"2015-11-30","to_date":"2016-02-01"}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Model Building and Testing"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5bf09265-2ce7-4bbb-b2dc-a0ce5cdd5106"}}},{"cell_type":"markdown","source":["Load the training data and add databricks paramaters"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1d84fa7a-598f-4832-b784-cfd109314f97"}}},{"cell_type":"code","source":["#Databricks paramaters to customize the runs\ndbutils.widgets.text(\"training_table\",training_table)\ndbutils.widgets.text(\"Model\", model_type)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"89a56399-807f-417c-95bc-92e05df5bffe"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{"training_table":{"name":"training_table","label":null,"widgetType":"text","options":{"widgetType":"text","validationRegex":null},"defaultValue":"training_data"},"Model":{"name":"Model","label":null,"widgetType":"text","options":{"widgetType":"text","validationRegex":null},"defaultValue":"RandomForest"}},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["spark.catalog.refreshTable(dbutils.widgets.get(\"training_table\")) \ntrain_data = spark.table(dbutils.widgets.get(\"training_table\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7daafca7-c78d-4110-bf6d-6bccb2a5ef61"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"train_data","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"machineID","nullable":true,"type":"long"},{"metadata":{},"name":"dt_truncated","nullable":true,"type":"timestamp"},{"metadata":{},"name":"volt_rollingmean_12","nullable":true,"type":"double"},{"metadata":{},"name":"rotate_rollingmean_12","nullable":true,"type":"double"},{"metadata":{},"name":"pressure_rollingmean_12","nullable":true,"type":"double"},{"metadata":{},"name":"vibration_rollingmean_12","nullable":true,"type":"double"},{"metadata":{},"name":"volt_rollingmean_24","nullable":true,"type":"double"},{"metadata":{},"name":"rotate_rollingmean_24","nullable":true,"type":"double"},{"metadata":{},"name":"pressure_rollingmean_24","nullable":true,"type":"double"},{"metadata":{},"name":"vibration_rollingmean_24","nullable":true,"type":"double"},{"metadata":{},"name":"volt_rollingmean_36","nullable":true,"type":"double"},{"metadata":{},"name":"vibration_rollingmean_36","nullable":true,"type":"double"},{"metadata":{},"name":"rotate_rollingmean_36","nullable":true,"type":"double"},{"metadata":{},"name":"pressure_rollingmean_36","nullable":true,"type":"double"},{"metadata":{},"name":"volt_rollingstd_12","nullable":true,"type":"double"},{"metadata":{},"name":"rotate_rollingstd_12","nullable":true,"type":"double"},{"metadata":{},"name":"pressure_rollingstd_12","nullable":true,"type":"double"},{"metadata":{},"name":"vibration_rollingstd_12","nullable":true,"type":"double"},{"metadata":{},"name":"volt_rollingstd_24","nullable":true,"type":"double"},{"metadata":{},"name":"rotate_rollingstd_24","nullable":true,"type":"double"},{"metadata":{},"name":"pressure_rollingstd_24","nullable":true,"type":"double"},{"metadata":{},"name":"vibration_rollingstd_24","nullable":true,"type":"double"},{"metadata":{},"name":"volt_rollingstd_36","nullable":true,"type":"double"},{"metadata":{},"name":"rotate_rollingstd_36","nullable":true,"type":"double"},{"metadata":{},"name":"pressure_rollingstd_36","nullable":true,"type":"double"},{"metadata":{},"name":"vibration_rollingstd_36","nullable":true,"type":"double"},{"metadata":{},"name":"error1sum_rollingmean_24","nullable":true,"type":"double"},{"metadata":{},"name":"error2sum_rollingmean_24","nullable":true,"type":"double"},{"metadata":{},"name":"error3sum_rollingmean_24","nullable":true,"type":"double"},{"metadata":{},"name":"error4sum_rollingmean_24","nullable":true,"type":"double"},{"metadata":{},"name":"error5sum_rollingmean_24","nullable":true,"type":"double"},{"metadata":{},"name":"comp1sum","nullable":true,"type":"double"},{"metadata":{},"name":"comp2sum","nullable":true,"type":"double"},{"metadata":{},"name":"comp3sum","nullable":true,"type":"double"},{"metadata":{},"name":"comp4sum","nullable":true,"type":"double"},{"metadata":{},"name":"model","nullable":true,"type":"string"},{"metadata":{},"name":"age","nullable":true,"type":"long"},{"metadata":{"ml_attr":{"attrs":{"binary":[{"idx":0,"name":"model3"},{"idx":1,"name":"model4"},{"idx":2,"name":"model2"}]},"num_attrs":3}},"name":"model_encoded","nullable":true,"type":{"class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"fields":[{"metadata":{},"name":"type","nullable":false,"type":"byte"},{"metadata":{},"name":"size","nullable":true,"type":"integer"},{"metadata":{},"name":"indices","nullable":true,"type":{"containsNull":false,"elementType":"integer","type":"array"}},{"metadata":{},"name":"values","nullable":true,"type":{"containsNull":false,"elementType":"double","type":"array"}}],"type":"struct"},"type":"udt"}},{"metadata":{},"name":"failure","nullable":true,"type":"double"},{"metadata":{},"name":"label_e","nullable":true,"type":"double"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{"training_table":"training_data"}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["# Prepare the Training data\n\nA fundamental practice in machine learning is to calibrate and test your model parameters on data that has not been used to train the model. <br> Evaluation of the model requires splitting the available data into a training portion, a calibration portion and an evaluation portion.<br> Typically, 80% of data is used to train the model and 10% each to calibrate any parameter selection and evaluate your model.\n\nIn general random splitting can be used, but since time series data have an inherent correlation between observations; for predictive maintenance problems,<br> a time-dependent spliting strategy is often a better approach to estimate performance. <br> For a time-dependent split, a single point in time is chosen, the model is trained on examples up to that point in time, and validated on the examples after that point. <br> This simulates training on current data and score data collected in the future data after the splitting point is not known. <br> However, care must be taken on labels near the split point. <br> In this case, feature records within 7 days of the split point can not be labeled as a failure, since that is unobserved data."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f39c55e6-6d47-4a70-9fa5-caf92f34feda"}}},{"cell_type":"code","source":["# define list of input columns for downstream modeling\n\n# We'll use the known label, and key variables.\nlabel_var = ['label_e']\nkey_cols =['machineID','dt_truncated']\n\n# Then get the remaining feature names from the data\ninput_features = train_data.columns\n\n# Remove the known label, key variables and a few extra columns we won't need.\nremove_names = label_var + key_cols + ['failure','model_encoded','model' ]\n\n# Create the iout features \ninput_features = [x for x in input_features if x not in set(remove_names)]"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b2cc40cb-85c4-4802-a412-c4e6e680c51a"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Spark models require a vectorized data frame. We transform the dataset here and then split the data into a training and test set. <br>\nWe use this split data to train the model on 9 months of data (training data), and evaluate on the remaining 3 months (test data) going forward."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cb75bdff-1e27-4267-8242-d102697b2691"}}},{"cell_type":"code","source":["# Import the libraries \nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import DecisionTreeClassifier\nfrom pyspark.ml.classification import RandomForestClassifier\n\n# for creating pipelines and model\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler, VectorIndexer\n\n# assemble features\nva = VectorAssembler(inputCols=(input_features), outputCol='features')\ntrain_data = va.transform(train_data).select('machineID','dt_truncated','label_e','features')\n\n# set maxCategories so features with > 10 distinct values are treated as continuous.\nfeatureIndexer = VectorIndexer(inputCol=\"features\", \n                               outputCol=\"indexedFeatures\", \n                               maxCategories=10).fit(train_data)\n\n# fit on whole dataset to include all labels in index\nlabelIndexer = StringIndexer(inputCol=\"label_e\", outputCol=\"indexedLabel\").fit(train_data)\n\ntraining = train_data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3a5f9330-7e40-48ea-8e4a-a2e5c66f00b2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"train_data","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"machineID","nullable":true,"type":"long"},{"metadata":{},"name":"dt_truncated","nullable":true,"type":"timestamp"},{"metadata":{},"name":"label_e","nullable":true,"type":"double"},{"metadata":{"ml_attr":{"attrs":{"numeric":[{"idx":0,"name":"volt_rollingmean_12"},{"idx":1,"name":"rotate_rollingmean_12"},{"idx":2,"name":"pressure_rollingmean_12"},{"idx":3,"name":"vibration_rollingmean_12"},{"idx":4,"name":"volt_rollingmean_24"},{"idx":5,"name":"rotate_rollingmean_24"},{"idx":6,"name":"pressure_rollingmean_24"},{"idx":7,"name":"vibration_rollingmean_24"},{"idx":8,"name":"volt_rollingmean_36"},{"idx":9,"name":"vibration_rollingmean_36"},{"idx":10,"name":"rotate_rollingmean_36"},{"idx":11,"name":"pressure_rollingmean_36"},{"idx":12,"name":"volt_rollingstd_12"},{"idx":13,"name":"rotate_rollingstd_12"},{"idx":14,"name":"pressure_rollingstd_12"},{"idx":15,"name":"vibration_rollingstd_12"},{"idx":16,"name":"volt_rollingstd_24"},{"idx":17,"name":"rotate_rollingstd_24"},{"idx":18,"name":"pressure_rollingstd_24"},{"idx":19,"name":"vibration_rollingstd_24"},{"idx":20,"name":"volt_rollingstd_36"},{"idx":21,"name":"rotate_rollingstd_36"},{"idx":22,"name":"pressure_rollingstd_36"},{"idx":23,"name":"vibration_rollingstd_36"},{"idx":24,"name":"error1sum_rollingmean_24"},{"idx":25,"name":"error2sum_rollingmean_24"},{"idx":26,"name":"error3sum_rollingmean_24"},{"idx":27,"name":"error4sum_rollingmean_24"},{"idx":28,"name":"error5sum_rollingmean_24"},{"idx":29,"name":"comp1sum"},{"idx":30,"name":"comp2sum"},{"idx":31,"name":"comp3sum"},{"idx":32,"name":"comp4sum"},{"idx":33,"name":"age"}]},"num_attrs":34}},"name":"features","nullable":true,"type":{"class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"fields":[{"metadata":{},"name":"type","nullable":false,"type":"byte"},{"metadata":{},"name":"size","nullable":true,"type":"integer"},{"metadata":{},"name":"indices","nullable":true,"type":{"containsNull":false,"elementType":"integer","type":"array"}},{"metadata":{},"name":"values","nullable":true,"type":{"containsNull":false,"elementType":"double","type":"array"}}],"type":"struct"},"type":"udt"}}],"type":"struct"},"tableIdentifier":null},{"name":"training","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"machineID","nullable":true,"type":"long"},{"metadata":{},"name":"dt_truncated","nullable":true,"type":"timestamp"},{"metadata":{},"name":"label_e","nullable":true,"type":"double"},{"metadata":{"ml_attr":{"attrs":{"numeric":[{"idx":0,"name":"volt_rollingmean_12"},{"idx":1,"name":"rotate_rollingmean_12"},{"idx":2,"name":"pressure_rollingmean_12"},{"idx":3,"name":"vibration_rollingmean_12"},{"idx":4,"name":"volt_rollingmean_24"},{"idx":5,"name":"rotate_rollingmean_24"},{"idx":6,"name":"pressure_rollingmean_24"},{"idx":7,"name":"vibration_rollingmean_24"},{"idx":8,"name":"volt_rollingmean_36"},{"idx":9,"name":"vibration_rollingmean_36"},{"idx":10,"name":"rotate_rollingmean_36"},{"idx":11,"name":"pressure_rollingmean_36"},{"idx":12,"name":"volt_rollingstd_12"},{"idx":13,"name":"rotate_rollingstd_12"},{"idx":14,"name":"pressure_rollingstd_12"},{"idx":15,"name":"vibration_rollingstd_12"},{"idx":16,"name":"volt_rollingstd_24"},{"idx":17,"name":"rotate_rollingstd_24"},{"idx":18,"name":"pressure_rollingstd_24"},{"idx":19,"name":"vibration_rollingstd_24"},{"idx":20,"name":"volt_rollingstd_36"},{"idx":21,"name":"rotate_rollingstd_36"},{"idx":22,"name":"pressure_rollingstd_36"},{"idx":23,"name":"vibration_rollingstd_36"},{"idx":24,"name":"error1sum_rollingmean_24"},{"idx":25,"name":"error2sum_rollingmean_24"},{"idx":26,"name":"error3sum_rollingmean_24"},{"idx":27,"name":"error4sum_rollingmean_24"},{"idx":28,"name":"error5sum_rollingmean_24"},{"idx":29,"name":"comp1sum"},{"idx":30,"name":"comp2sum"},{"idx":31,"name":"comp3sum"},{"idx":32,"name":"comp4sum"},{"idx":33,"name":"age"}]},"num_attrs":34}},"name":"features","nullable":true,"type":{"class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"fields":[{"metadata":{},"name":"type","nullable":false,"type":"byte"},{"metadata":{},"name":"size","nullable":true,"type":"integer"},{"metadata":{},"name":"indices","nullable":true,"type":{"containsNull":false,"elementType":"integer","type":"array"}},{"metadata":{},"name":"values","nullable":true,"type":{"containsNull":false,"elementType":"double","type":"array"}}],"type":"struct"},"type":"udt"}}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Prepare the Testing Data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"634f7a2d-1d84-4048-b6e5-1e0fa856676d"}}},{"cell_type":"markdown","source":["To evaluate this model, we predict the component failures over the test data set.<br> Since the test set has been created from data the model has not been seen before, it simulates future data. <br> The evaluation can then be generalized to assess how the model could perform when operationalized and used to score new data."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3be2834b-db98-4594-b183-9932d41943ce"}}},{"cell_type":"code","source":["testing_table = 'testing_data'\ndbutils.widgets.removeAll()\ndbutils.widgets.text(\"Testing_table\",testing_table)\ndbutils.widgets.text(\"Model\", model_type)\ndbutils.widgets.text(\"start_date\", '2015-11-30')\ndbutils.widgets.text(\"to_date\", '2016-02-01')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"19378576-6c53-42a9-aca5-a1c1990c1990"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":["model","training_table","features_table"],"addedWidgets":{"Testing_table":{"name":"Testing_table","label":null,"widgetType":"text","options":{"widgetType":"text","validationRegex":null},"defaultValue":"testing_data"},"start_date":{"name":"start_date","label":null,"widgetType":"text","options":{"widgetType":"text","validationRegex":null},"defaultValue":"2015-11-30"},"Model":{"name":"Model","label":null,"widgetType":"text","options":{"widgetType":"text","validationRegex":null},"defaultValue":"RandomForest"},"to_date":{"name":"to_date","label":null,"widgetType":"text","options":{"widgetType":"text","validationRegex":null},"defaultValue":"2016-02-01"}},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["spark.catalog.setCurrentDatabase(\"default\")\nexists = False\nfor tbl in spark.catalog.listTables():\n  if tbl.name == dbutils.widgets.get(\"Testing_table\"):\n    exists = True\n    break"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"476fcf09-5ad0-458d-bc77-efe01731007e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{"Testing_table":"testing_data"}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["if not exists:\n  dbutils.notebook.run(\"2_Feature_Engineering\", 600, {\"features_table\": dbutils.widgets.get(\"Testing_table\"), \n                                                       \"start_date\": dbutils.widgets.get(\"start_date\"), \n                                                       \"to_date\": dbutils.widgets.get(\"to_date\")})"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2800f39a-2d83-42e6-8bc4-f69106d02bad"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#Load the data\n\ntest_data = spark.table(dbutils.widgets.get(\"Testing_table\"))\n\n# Testing data is prepared using the same steps used for the traning data \n\n# define list of input columns for downstream modeling\n\n# We'll use the known label, and key variables.\nlabel_var = ['label_e']\nkey_cols =['machineID','dt_truncated']\n\n# Then get the remaining feature names from the data\ninput_features = test_data.columns\n\n# Remove the known label, key variables and a few extra columns we won't need.\nremove_names = label_var + key_cols + ['failure','model_encoded','model' ]\n\n# Create the iout features \ninput_features = [x for x in input_features if x not in set(remove_names)]\n\n# assemble features\nva = VectorAssembler(inputCols=(input_features), outputCol='features')\n\n# assemble features\ntest_data = va.transform(test_data).select('machineID','dt_truncated','label_e','features')\n\n# set maxCategories so features with > 10 distinct values are treated as continuous.\nfeatureIndexer = VectorIndexer(inputCol=\"features\", \n                               outputCol=\"indexedFeatures\", \n                               maxCategories=10).fit(test_data)\n\n# fit on whole dataset to include all labels in index\nlabelIndexer = StringIndexer(inputCol=\"label_e\", outputCol=\"indexedLabel\").fit(test_data)\n\ntesting = test_data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3a6087ce-190e-4e6a-9079-697c6b132677"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"test_data","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"machineID","nullable":true,"type":"long"},{"metadata":{},"name":"dt_truncated","nullable":true,"type":"timestamp"},{"metadata":{},"name":"label_e","nullable":true,"type":"double"},{"metadata":{"ml_attr":{"attrs":{"numeric":[{"idx":0,"name":"volt_rollingmean_12"},{"idx":1,"name":"rotate_rollingmean_12"},{"idx":2,"name":"pressure_rollingmean_12"},{"idx":3,"name":"vibration_rollingmean_12"},{"idx":4,"name":"volt_rollingmean_24"},{"idx":5,"name":"rotate_rollingmean_24"},{"idx":6,"name":"pressure_rollingmean_24"},{"idx":7,"name":"vibration_rollingmean_24"},{"idx":8,"name":"volt_rollingmean_36"},{"idx":9,"name":"vibration_rollingmean_36"},{"idx":10,"name":"rotate_rollingmean_36"},{"idx":11,"name":"pressure_rollingmean_36"},{"idx":12,"name":"volt_rollingstd_12"},{"idx":13,"name":"rotate_rollingstd_12"},{"idx":14,"name":"pressure_rollingstd_12"},{"idx":15,"name":"vibration_rollingstd_12"},{"idx":16,"name":"volt_rollingstd_24"},{"idx":17,"name":"rotate_rollingstd_24"},{"idx":18,"name":"pressure_rollingstd_24"},{"idx":19,"name":"vibration_rollingstd_24"},{"idx":20,"name":"volt_rollingstd_36"},{"idx":21,"name":"rotate_rollingstd_36"},{"idx":22,"name":"pressure_rollingstd_36"},{"idx":23,"name":"vibration_rollingstd_36"},{"idx":24,"name":"error1sum_rollingmean_24"},{"idx":25,"name":"error2sum_rollingmean_24"},{"idx":26,"name":"error3sum_rollingmean_24"},{"idx":27,"name":"error4sum_rollingmean_24"},{"idx":28,"name":"error5sum_rollingmean_24"},{"idx":29,"name":"comp1sum"},{"idx":30,"name":"comp2sum"},{"idx":31,"name":"comp3sum"},{"idx":32,"name":"comp4sum"},{"idx":33,"name":"age"}]},"num_attrs":34}},"name":"features","nullable":true,"type":{"class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"fields":[{"metadata":{},"name":"type","nullable":false,"type":"byte"},{"metadata":{},"name":"size","nullable":true,"type":"integer"},{"metadata":{},"name":"indices","nullable":true,"type":{"containsNull":false,"elementType":"integer","type":"array"}},{"metadata":{},"name":"values","nullable":true,"type":{"containsNull":false,"elementType":"double","type":"array"}}],"type":"struct"},"type":"udt"}}],"type":"struct"},"tableIdentifier":null},{"name":"testing","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"machineID","nullable":true,"type":"long"},{"metadata":{},"name":"dt_truncated","nullable":true,"type":"timestamp"},{"metadata":{},"name":"label_e","nullable":true,"type":"double"},{"metadata":{"ml_attr":{"attrs":{"numeric":[{"idx":0,"name":"volt_rollingmean_12"},{"idx":1,"name":"rotate_rollingmean_12"},{"idx":2,"name":"pressure_rollingmean_12"},{"idx":3,"name":"vibration_rollingmean_12"},{"idx":4,"name":"volt_rollingmean_24"},{"idx":5,"name":"rotate_rollingmean_24"},{"idx":6,"name":"pressure_rollingmean_24"},{"idx":7,"name":"vibration_rollingmean_24"},{"idx":8,"name":"volt_rollingmean_36"},{"idx":9,"name":"vibration_rollingmean_36"},{"idx":10,"name":"rotate_rollingmean_36"},{"idx":11,"name":"pressure_rollingmean_36"},{"idx":12,"name":"volt_rollingstd_12"},{"idx":13,"name":"rotate_rollingstd_12"},{"idx":14,"name":"pressure_rollingstd_12"},{"idx":15,"name":"vibration_rollingstd_12"},{"idx":16,"name":"volt_rollingstd_24"},{"idx":17,"name":"rotate_rollingstd_24"},{"idx":18,"name":"pressure_rollingstd_24"},{"idx":19,"name":"vibration_rollingstd_24"},{"idx":20,"name":"volt_rollingstd_36"},{"idx":21,"name":"rotate_rollingstd_36"},{"idx":22,"name":"pressure_rollingstd_36"},{"idx":23,"name":"vibration_rollingstd_36"},{"idx":24,"name":"error1sum_rollingmean_24"},{"idx":25,"name":"error2sum_rollingmean_24"},{"idx":26,"name":"error3sum_rollingmean_24"},{"idx":27,"name":"error4sum_rollingmean_24"},{"idx":28,"name":"error5sum_rollingmean_24"},{"idx":29,"name":"comp1sum"},{"idx":30,"name":"comp2sum"},{"idx":31,"name":"comp3sum"},{"idx":32,"name":"comp4sum"},{"idx":33,"name":"age"}]},"num_attrs":34}},"name":"features","nullable":true,"type":{"class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"fields":[{"metadata":{},"name":"type","nullable":false,"type":"byte"},{"metadata":{},"name":"size","nullable":true,"type":"integer"},{"metadata":{},"name":"indices","nullable":true,"type":{"containsNull":false,"elementType":"integer","type":"array"}},{"metadata":{},"name":"values","nullable":true,"type":{"containsNull":false,"elementType":"double","type":"array"}}],"type":"struct"},"type":"udt"}}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{"Testing_table":"testing_data"}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Classification Models\n\nA particular problem in predictive maintenance is machine failures are usually rare occurrences compared to normal operation. This is fortunate for the business as maintenance and saftey issues are few, but causes an imbalance in the label distribution. This imbalance leads to poor performance as algorithms tend to classify majority class examples at the expense of minority class, since the total misclassification error is much improved when majority class is labeled correctly. This causes low recall or precision rates, although accuracy can be high. It becomes a larger problem when the cost of false alarms is very high. To help with this problem, sampling techniques such as oversampling of the minority examples can be used. These methods are not covered in this notebook. Because of this, it is also important to look at evaluation metrics other than accuracy alone.\n\nWe will build a Random Forest Classifier:\n\n- **Random Forest Classifier**: A random forest is an ensemble of decision trees. Random forests combine many decision trees in order to reduce the risk of overfitting. Tree ensemble algorithms such as random forests and boosting are among the top performers for classification and regression tasks.\n\nThe next code block creates the model. A series of model hyperparametershave also been included to guide your exploration of the model space."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b7f8506b-ff94-433c-abb7-694b32f1934a"}}},{"cell_type":"code","source":["# import the libraries for creating pipelines and model\n\nfrom pyspark.sql import SparkSession\nimport numpy as np\nfrom pyspark.ml import PipelineModel\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import RandomForestClassifier\nfrom pyspark.ml.feature import StringIndexer, VectorAssembler, VectorIndexer\n\n \nrf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", \n                            # Passed to DecisionTreeClassifier\n                            maxDepth=15, \n                            maxBins=32, \n                            minInstancesPerNode=1, \n                            minInfoGain=0.0,\n                            impurity=\"gini\",\n                            # Number of trees to train (>= 1)\n                            numTrees=200, \n                            # The number of features to consider for splits at each tree node. \n                            # Supported options: auto, all, onethird, sqrt, log2, (0.0-1.0], [1-n].\n                            featureSubsetStrategy=\"sqrt\", \n                            # Fraction of the training data used for learning each  \n                            # decision tree, in range (0, 1].' \n                            subsamplingRate = 0.632)\n  \n# chain indexers and model in a Pipeline\npipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf])\n  \n# train model.  This also runs the indexers.\nmodel = pipeline.fit(training)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"91bc622e-4886-4553-9470-a67d0d794779"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["###Persist the model\n\nHere we save the model in a paraquet file on DBFS\n\nIn other words we have now stored the model on the Azure Databricks files system."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1763d6e5-0f9c-405a-817b-6c3c354dbb83"}}},{"cell_type":"code","source":["# save model\nmodel.write().overwrite().save(\"dbfs:/storage/models/\" + model_type + \".pqt\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4e4a7319-e742-4d01-b706-dc9fb61fca78"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Model Testing"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b4787824-a181-4759-bce8-daef27a39f71"}}},{"cell_type":"markdown","source":["Load the model so that we can test it on new data"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b22a3925-4090-44b8-9ecf-87b3d664b2eb"}}},{"cell_type":"code","source":["model_pipeline = PipelineModel.load(\"dbfs:/storage/models/\" + dbutils.widgets.get(\"Model\") + \".pqt\")\n\nprint(\"Model loaded\")\nmodel_pipeline"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ad90d2f4-a127-4098-adaa-2c0ec0284fbd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Model loaded\nOut[14]: PipelineModel_6f5b5676a24b</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{"Model":"RandomForest"}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Model loaded\nOut[14]: PipelineModel_6f5b5676a24b</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Test the model on new data and calculate a set of model evaluation metrics to help us know how well the model may perform in a production setting."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"275ee92a-db67-4bd2-b07d-68a0901aa9c6"}}},{"cell_type":"code","source":["# make predictions. The Pipeline does all the same operations on the test data\npredictions = model.transform(testing)\n \n# Create the confusion matrix for the multiclass prediction results\n# This result assumes a decision boundary of p = 0.5\nconf_table = predictions.stat.crosstab('indexedLabel', 'prediction')\nconfuse = conf_table.toPandas()\nconfuse.head()\n  \n# Log MLflow Metrics and Model\n# select (prediction, true label) and compute test error\n# select (prediction, true label) and compute test error\n# True positives - diagonal failure terms\ntp = confuse['1.0'][1]+confuse['2.0'][2]+confuse['3.0'][3]+confuse['4.0'][4]\n# False positves - All failure terms - True positives\nfp = np.sum(np.sum(confuse[['1.0', '2.0','3.0','4.0']])) - tp\n# True negatives \ntn = confuse['0.0'][0]\n# False negatives total of non-failure column - TN\nfn = np.sum(np.sum(confuse[['0.0']])) - tn\n  \n# Accuracy is diagonal/total \nacc_n = tn + tp\nacc_d = np.sum(np.sum(confuse[['0.0','1.0', '2.0','3.0','4.0']]))\nacc = acc_n/acc_d\n  \n# Calculate precision and recall.\nprec = tp/(tp+fp)\nrec = tp/(tp+fn)\n  \n# Calculate F1\nFOne = 2.0 * prec * rec/(prec + rec)\n  \n# Print the evaluation metrics to the notebook\nprint(\"Accuracy = %g\" % acc)\nprint(\"Precision = %g\" % prec)\nprint(\"Recall = %g\" % rec )\nprint(\"F1 = %g\" % (2.0 * prec * rec/(prec + rec)))\nprint(\"\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c4a3279c-a9ff-4880-b342-f7e964afbf4d"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"predictions","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"machineID","nullable":true,"type":"long"},{"metadata":{},"name":"dt_truncated","nullable":true,"type":"timestamp"},{"metadata":{},"name":"label_e","nullable":true,"type":"double"},{"metadata":{"ml_attr":{"attrs":{"numeric":[{"idx":0,"name":"volt_rollingmean_12"},{"idx":1,"name":"rotate_rollingmean_12"},{"idx":2,"name":"pressure_rollingmean_12"},{"idx":3,"name":"vibration_rollingmean_12"},{"idx":4,"name":"volt_rollingmean_24"},{"idx":5,"name":"rotate_rollingmean_24"},{"idx":6,"name":"pressure_rollingmean_24"},{"idx":7,"name":"vibration_rollingmean_24"},{"idx":8,"name":"volt_rollingmean_36"},{"idx":9,"name":"vibration_rollingmean_36"},{"idx":10,"name":"rotate_rollingmean_36"},{"idx":11,"name":"pressure_rollingmean_36"},{"idx":12,"name":"volt_rollingstd_12"},{"idx":13,"name":"rotate_rollingstd_12"},{"idx":14,"name":"pressure_rollingstd_12"},{"idx":15,"name":"vibration_rollingstd_12"},{"idx":16,"name":"volt_rollingstd_24"},{"idx":17,"name":"rotate_rollingstd_24"},{"idx":18,"name":"pressure_rollingstd_24"},{"idx":19,"name":"vibration_rollingstd_24"},{"idx":20,"name":"volt_rollingstd_36"},{"idx":21,"name":"rotate_rollingstd_36"},{"idx":22,"name":"pressure_rollingstd_36"},{"idx":23,"name":"vibration_rollingstd_36"},{"idx":24,"name":"error1sum_rollingmean_24"},{"idx":25,"name":"error2sum_rollingmean_24"},{"idx":26,"name":"error3sum_rollingmean_24"},{"idx":27,"name":"error4sum_rollingmean_24"},{"idx":28,"name":"error5sum_rollingmean_24"},{"idx":29,"name":"comp1sum"},{"idx":30,"name":"comp2sum"},{"idx":31,"name":"comp3sum"},{"idx":32,"name":"comp4sum"},{"idx":33,"name":"age"}]},"num_attrs":34}},"name":"features","nullable":true,"type":{"class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"fields":[{"metadata":{},"name":"type","nullable":false,"type":"byte"},{"metadata":{},"name":"size","nullable":true,"type":"integer"},{"metadata":{},"name":"indices","nullable":true,"type":{"containsNull":false,"elementType":"integer","type":"array"}},{"metadata":{},"name":"values","nullable":true,"type":{"containsNull":false,"elementType":"double","type":"array"}}],"type":"struct"},"type":"udt"}},{"metadata":{"ml_attr":{"name":"indexedLabel","type":"nominal","vals":["0.0","2.0","1.0","4.0","3.0"]}},"name":"indexedLabel","nullable":false,"type":"double"},{"metadata":{"ml_attr":{"attrs":{"numeric":[{"idx":0,"name":"volt_rollingmean_12"},{"idx":1,"name":"rotate_rollingmean_12"},{"idx":2,"name":"pressure_rollingmean_12"},{"idx":3,"name":"vibration_rollingmean_12"},{"idx":4,"name":"volt_rollingmean_24"},{"idx":5,"name":"rotate_rollingmean_24"},{"idx":6,"name":"pressure_rollingmean_24"},{"idx":7,"name":"vibration_rollingmean_24"},{"idx":8,"name":"volt_rollingmean_36"},{"idx":9,"name":"vibration_rollingmean_36"},{"idx":10,"name":"rotate_rollingmean_36"},{"idx":11,"name":"pressure_rollingmean_36"},{"idx":12,"name":"volt_rollingstd_12"},{"idx":13,"name":"rotate_rollingstd_12"},{"idx":14,"name":"pressure_rollingstd_12"},{"idx":15,"name":"vibration_rollingstd_12"},{"idx":16,"name":"volt_rollingstd_24"},{"idx":17,"name":"rotate_rollingstd_24"},{"idx":18,"name":"pressure_rollingstd_24"},{"idx":19,"name":"vibration_rollingstd_24"},{"idx":20,"name":"volt_rollingstd_36"},{"idx":21,"name":"rotate_rollingstd_36"},{"idx":22,"name":"pressure_rollingstd_36"},{"idx":23,"name":"vibration_rollingstd_36"},{"idx":24,"name":"error1sum_rollingmean_24"},{"idx":25,"name":"error2sum_rollingmean_24"},{"idx":26,"name":"error3sum_rollingmean_24"},{"idx":27,"name":"error4sum_rollingmean_24"},{"idx":28,"name":"error5sum_rollingmean_24"},{"idx":29,"name":"comp1sum"},{"idx":30,"name":"comp2sum"},{"idx":31,"name":"comp3sum"},{"idx":32,"name":"comp4sum"},{"idx":33,"name":"age"}]},"num_attrs":34}},"name":"indexedFeatures","nullable":true,"type":{"class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"fields":[{"metadata":{},"name":"type","nullable":false,"type":"byte"},{"metadata":{},"name":"size","nullable":true,"type":"integer"},{"metadata":{},"name":"indices","nullable":true,"type":{"containsNull":false,"elementType":"integer","type":"array"}},{"metadata":{},"name":"values","nullable":true,"type":{"containsNull":false,"elementType":"double","type":"array"}}],"type":"struct"},"type":"udt"}},{"metadata":{"ml_attr":{"num_attrs":5}},"name":"rawPrediction","nullable":true,"type":{"class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"fields":[{"metadata":{},"name":"type","nullable":false,"type":"byte"},{"metadata":{},"name":"size","nullable":true,"type":"integer"},{"metadata":{},"name":"indices","nullable":true,"type":{"containsNull":false,"elementType":"integer","type":"array"}},{"metadata":{},"name":"values","nullable":true,"type":{"containsNull":false,"elementType":"double","type":"array"}}],"type":"struct"},"type":"udt"}},{"metadata":{"ml_attr":{"num_attrs":5}},"name":"probability","nullable":true,"type":{"class":"org.apache.spark.ml.linalg.VectorUDT","pyClass":"pyspark.ml.linalg.VectorUDT","sqlType":{"fields":[{"metadata":{},"name":"type","nullable":false,"type":"byte"},{"metadata":{},"name":"size","nullable":true,"type":"integer"},{"metadata":{},"name":"indices","nullable":true,"type":{"containsNull":false,"elementType":"integer","type":"array"}},{"metadata":{},"name":"values","nullable":true,"type":{"containsNull":false,"elementType":"double","type":"array"}}],"type":"struct"},"type":"udt"}},{"metadata":{"ml_attr":{"num_vals":5,"type":"nominal"}},"name":"prediction","nullable":false,"type":"double"}],"type":"struct"},"tableIdentifier":null},{"name":"conf_table","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"indexedLabel_prediction","nullable":true,"type":"string"},{"metadata":{},"name":"0.0","nullable":true,"type":"long"},{"metadata":{},"name":"1.0","nullable":true,"type":"long"},{"metadata":{},"name":"2.0","nullable":true,"type":"long"},{"metadata":{},"name":"3.0","nullable":true,"type":"long"},{"metadata":{},"name":"4.0","nullable":true,"type":"long"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">Accuracy = 0.960505\nPrecision = 0.985396\nRecall = 0.353896\nF1 = 0.520764\n\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy = 0.960505\nPrecision = 0.985396\nRecall = 0.353896\nF1 = 0.520764\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Conclusion\nThis notebook demonstrated how to train, store, load and test a model on new data as well as how to calculate a set of model evaluation metrics to help us assess how well the model may perform in a production setting.\n\nThe 4_Scoring_Pipeline notebook takes parameters to define the data to be scored, and using the model created here, calculates the probability of component failure in the machine population specified."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"026eeb0a-c89d-44dd-a9bf-37a859d28e4b"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"3_Model_Building_And_Training","dashboards":[],"language":"python","widgets":{"Testing_table":{"nuid":"6f2f82f3-58b4-4ffa-acb5-6ca626abff73","currentValue":"testing_data","widgetInfo":{"widgetType":"text","name":"Testing_table","defaultValue":"testing_data","label":null,"options":{"widgetType":"text","validationRegex":null}}},"start_date":{"nuid":"d3390958-1a0f-48a5-b09a-af58b107576e","currentValue":"2015-11-30","widgetInfo":{"widgetType":"text","name":"start_date","defaultValue":"2015-11-30","label":null,"options":{"widgetType":"text","validationRegex":null}}},"Model":{"nuid":"a61f95c2-07d0-4d2e-a531-e70990f165b3","currentValue":"RandomForest","widgetInfo":{"widgetType":"text","name":"Model","defaultValue":"RandomForest","label":null,"options":{"widgetType":"text","validationRegex":null}}},"to_date":{"nuid":"1835029f-fba7-4a50-bd4b-238428e4be94","currentValue":"2016-02-01","widgetInfo":{"widgetType":"text","name":"to_date","defaultValue":"2016-02-01","label":null,"options":{"widgetType":"text","validationRegex":null}}}},"notebookOrigID":4105559978712102}},"nbformat":4,"nbformat_minor":0}
